- Em todos os exercícios, definir o conjunto de estados e desenhar a cadeia para classificar os estados.

- Definição de poisson com lambda t
    - P(N(t) = k) = e^-{\lambda t} * (\lambda t)^k/k!
- Binomial -> Poisson
- Notação N(t) = N((0, t])
    - N((s, t]) = N((0, t]) - N((0, s]) = N(t) - N(s) = N(t-s)
- Incrementos independentes: para todo s < t, o número de ocorrências N(t) − N(s) (incrementos) no
intervalo (s, t] é independente das ocorrências em [0, s]
    - P(N(s + t) − N(s) = k) = P(N(t) = k)
- Incrementos estacionários: P(N(t) - N(s) = n-k) = P(N(t-s) = n-k)
- Instantes de ocorrência: Chamado de S_i e denota o tempo da i-ésima ocorrência. S_i ~ Gama(i, \lambda)
- Tempos entre chegadas: T_k = S_k - S_{k-1}. T_k ~ Exponencial (\lambda). Os T_i são independentes entre si.

- Partição do processo de Poisson. Seja N(t) um processo de Poisson(\lambda) em que seja possível classificar cada evento entre uma classe A ou B com prob. p e 1-p. Define-se dois processos de Poisson A(t) e B(t) com parâmetros \lambda p e \lambda (1-p), independentes
- Superposição dos processos. Sejam dois processos N_1(t), com parametro \lambda_1 e N_2(t), com parametro \lambda_2. É possível fazer N = N_1 + N_2 com parametro \lambda = \lambda_1 + \lambda_2

- Propriedade Markoviana: P(X(t+s) = j | X(s) = i, X(u) = x_u, 0 <= u < s) = P(X(t+s) = j | X(s) = i) = p_{ij}(s, t+s) = p_{ij}(0, t) = p_{ij}(t)
- O tempo de permanência no estado deve satisfazer P(T_i > s+t | T_i > s) = P(T_i > t), que é a propriedade da falta de memória. Assim, a propriedade Markoviana induz a tempos de permanência
exponenciais.
- Processo de nascimento e morte. Estando no estado k, o processo só pode ir para k-1 e k+1. Fazendo N_k: o tempo de ocorrência de um nascimento se há k pessoas e M_k: o tempo de ocorrência se há k pessoas, N_k~Exponencial(\lambda_k) e M_k~Exponencial(\lambda_k). 
    - A transição ocorrerá após um tempo T_k. Esse tempo é o tempo de ocorrer o primeiro evento, ou seja, o mínimo entre N_k e M_k, logo: T_k  = min{N_k, M_k} -> T_k ~ Exponencial(\lambda_k + \mu_k).
    - A prob. de ir para k-1 é P(N_k < M_k) = \frac{\lambda_k}{\lambda_k + \mu_k} e de ir para k+1 é P(N_k >= M_k) = \frac{\mu_k}{\lambda_k + \mu_k} 

- O processo de Poisson de taxa \lambda é um processo Markoviano. Ele tem probabilidade = 1 de ir do estado k para o k+1. A taxa de morte é \mu_n = 0 e a de nascimento é \lambda_n = lambda, para todo n >= 0.
- Lembrar das equações de Chapman-Kolmogorov:
    - P(s+t) = P(s)P(t) (representação matricial)

- Gerador infinitesimal: P'_t = G P_t. Lembrar que P_t = e^tG. Esse gerador nada mais é do que uma matriz com as taxas de transição instantâneas de um estado i para um estado j. As linhas têm que somar 0.

- Cadeia embutida:

- Não há periodiciade em tempo contínuo. 
    - O processo é irredutível <-> A cadeia embutida é irredutível.
    - Um estado é recorrente <-> Ele é recorrente para a cadeia embutida.
    - Se o tempo médio de retorno ao estado i é finito -> O estado i é recorrente positivo.

- Distribuição estacionária. \pi = \pi P(t), para todo t >= 0 e \sum_{i \in S} \pi_i = 1.
    - \pi = \pi P(t) <-> \pi G = 0
    - Se em uma cadeia irredutível existe uma distribuição estacionária \pi ela é única e lim t->inf p_{ij}(t) = \pi_j, para todo i, j \in S.
    - Se ela não existe, então o p_{ij} -> 0 quando t -> inf para todo i, j \in S.

- Reversibilidade. Seja {X(t), t >= 0} uma cadeia de Markov em tempo contínuo, com gerador infinitesimal G com distribuição estacionária \pi. Se existe um vetor \alpha que satisfaz as equações de balanço detalhado: \alpha_i g_{ij} = \alpha_j g_{ji}, e \sum_{k \in S} \alpha_k = 1, o processo é reversível e \alpha = \pi é a distribuição estacionária.